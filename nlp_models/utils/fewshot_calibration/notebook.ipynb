{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated Probabilities: [2.155807e-39 2.271295e-39 2.152010e-39 ... 2.150451e-39 2.151042e-39\n",
      " 2.171290e-39]\n",
      "Predicted Class: 33733\n",
      "Calibrated Probabilities: 0.9999998807907104\n",
      "Predicted Class:  Positive\n",
      "Original Predicted Class:  Negative\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "def get_logits(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.logits[0, -1, :]  # 마지막 토큰에 대한 logits 반환\n",
    "\n",
    "def contextual_calibration(model, tokenizer, few_shot_prompt, test_prompt, content_free_inputs):\n",
    "    \"\"\"\n",
    "    Few-shot Prompting 기반 Contextual Calibration 구현.\n",
    "    Args:\n",
    "        model: 로드된 GPT-like 모델.\n",
    "        tokenizer: 해당 모델의 토크나이저.\n",
    "        few_shot_prompt (str): Few-shot 예제 포함 프롬프트.\n",
    "        test_prompt (str): 테스트 프롬프트.\n",
    "        content_free_inputs (list): Content-free 입력 리스트 (e.g., [\"N/A\", \"\", \"[MASK]\"]).\n",
    "    Returns:\n",
    "        calibrated_probs (np.array): 보정된 확률.\n",
    "        predicted_class (int): 보정된 클래스.\n",
    "    \"\"\"\n",
    "    # 1. Content-Free Input에 대한 logits 계산\n",
    "    baseline_probs = []\n",
    "    for cfi in content_free_inputs:\n",
    "        cfi_prompt = few_shot_prompt + cfi\n",
    "        logits = get_logits(model, tokenizer, cfi_prompt)\n",
    "        probs = softmax(logits.detach().numpy())\n",
    "        baseline_probs.append(probs)\n",
    "\n",
    "    # Content-Free 평균 확률 계산\n",
    "    baseline_probs = np.mean(baseline_probs, axis=0)\n",
    "\n",
    "    # 2. 테스트 프롬프트에 대한 logits 계산\n",
    "    test_logits = get_logits(model, tokenizer, few_shot_prompt + test_prompt)\n",
    "    test_probs = softmax(test_logits.detach().numpy())\n",
    "\n",
    "    # original predicted class\n",
    "    original_predicted_class = np.argmax(test_probs)\n",
    "\n",
    "    # 3. Affine Transformation 적용\n",
    "    W = np.diag(1.0 / baseline_probs)  # 대각 행렬\n",
    "    b = np.zeros_like(baseline_probs)  # 편향\n",
    "    calibrated_probs = softmax(np.dot(W, test_probs) + b)\n",
    "\n",
    "    # 4. 최종 클래스 예측\n",
    "    predicted_class = np.argmax(calibrated_probs)\n",
    "    return calibrated_probs, predicted_class, test_probs, original_predicted_class\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"gpt2\"  # 필요에 따라 다른 모델 사용 가능\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Few-shot Prompt와 테스트 데이터 설정\n",
    "few_shot_prompt = \"\"\"Input: Subpar acting. Sentiment: Negative\n",
    "Input: Beautiful film. Sentiment: Positive\n",
    "Input:\"\"\"\n",
    "test_prompt = \"This movie was dull and boring. Sentiment:\"\n",
    "content_free_inputs = [\"N/A\", \"\", \"[MASK]\"]\n",
    "\n",
    "# 실행\n",
    "calibrated_probs, predicted_class, test_probs, original_predicted_class = contextual_calibration(\n",
    "    model, tokenizer, few_shot_prompt, test_prompt, content_free_inputs\n",
    ")\n",
    "\n",
    "print(\"Calibrated Probabilities:\", calibrated_probs)\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(f\"Calibrated Probabilities: {calibrated_probs[predicted_class]}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"Predicted Class: {tokenizer.decode(predicted_class)}\")\n",
    "print(f\"Original Predicted Class: {tokenizer.decode(original_predicted_class)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
